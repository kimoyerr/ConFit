{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add confit to sys.path\n",
    "import sys\n",
    "sys.path.append(\"/ConFit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import os\n",
    "import warnings\n",
    "import time\n",
    "import yaml\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import accelerate\n",
    "from accelerate import Accelerator\n",
    "from accelerate.utils import set_seed\n",
    "from transformers import EsmForMaskedLM, EsmTokenizer, EsmConfig\n",
    "from peft import PeftModel, PeftConfig, LoraConfig, get_peft_model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from confit.data_utils import Mutation_Set, split_train, sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Args\n",
    "config_file = \"/ConFit/config/training_config.yaml\"\n",
    "dataset = \"GB1_Olson2014_ddg\"\n",
    "model_seed = 1\n",
    "sample_seed = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in configa\n",
    "with open(f'{config_file}', 'r', encoding='utf-8') as f:\n",
    "    config = yaml.load(f.read(), Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = int(int(config['batch_size'])/int(config['gpu_number']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ESM-1v is better for zero-shot predictions of mutations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from confit.train import train, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    r=int(config['lora_r']),\n",
    "    lora_alpha=int(config['lora_alpha']),\n",
    "    lora_dropout=float(config['lora_dropout']),\n",
    "    target_modules=[\"query\", \"value\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def training_loop(mixed_precision=\"fp16\", seed: int = 42, batch_size: int = 64):\n",
    "    set_seed(seed)\n",
    "    # Initialize accelerator\n",
    "    accelerator = Accelerator(mixed_precision=mixed_precision)\n",
    "\n",
    "    # Model\n",
    "    if config['model'] == 'ESM-1v':\n",
    "        basemodel = EsmForMaskedLM.from_pretrained(f'facebook/esm1v_t33_650M_UR90S_{model_seed}')\n",
    "        model_reg = EsmForMaskedLM.from_pretrained(f'facebook/esm1v_t33_650M_UR90S_{model_seed}')\n",
    "        tokenizer = EsmTokenizer.from_pretrained(f'facebook/esm1v_t33_650M_UR90S_{model_seed}')\n",
    "\n",
    "    for pm in model_reg.parameters():\n",
    "        pm.requires_grad = False\n",
    "    model_reg.eval()    #regularization model\n",
    "    model = get_peft_model(basemodel, peft_config)\n",
    "    \n",
    "    # create optimizer and scheduler\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=float(config['ini_lr']))\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=2*int(config['max_epochs']), eta_min=float(config['min_lr']))\n",
    "    if os.environ.get(\"ACCELERATE_USE_FSDP\", None) is not None:\n",
    "        accelerator.state.fsdp_plugin.auto_wrap_policy = fsdp_auto_wrap_policy(model)\n",
    "    \n",
    "    # Prepare model\n",
    "    model, optimizer, scheduler = accelerator.prepare(model, optimizer, scheduler)\n",
    "    model_reg = accelerator.prepare(model_reg)\n",
    "\n",
    "    # Load data\n",
    "    if accelerator.is_main_process:\n",
    "        sample_data(dataset, sample_seed, int(config['shot']))\n",
    "        split_train(dataset)\n",
    "\n",
    "    with accelerator.main_process_first():\n",
    "        train_csv = pd.DataFrame(None)\n",
    "        test_csv = pd.read_csv(f'../data/{dataset}/test.csv')\n",
    "        for i in range(1, 6):\n",
    "            if i == model_seed:\n",
    "                val_csv = pd.read_csv(f'../data/{dataset}/train_{i}.csv')   #using 1/5 train data as validation set\n",
    "            temp_csv = pd.read_csv(f'../data/{dataset}/train_{i}.csv')\n",
    "            train_csv = pd.concat([train_csv, temp_csv], axis=0)\n",
    "    \n",
    "    #create dataset and dataloader\n",
    "    trainset = Mutation_Set(data=train_csv, fname=dataset, tokenizer=tokenizer)\n",
    "    testset = Mutation_Set(data=test_csv, fname=dataset,  tokenizer=tokenizer)\n",
    "    valset = Mutation_Set(data=val_csv, fname=dataset,  tokenizer=tokenizer)\n",
    "\n",
    "    with accelerator.main_process_first():\n",
    "        trainloader = DataLoader(trainset, batch_size=batch_size, collate_fn=trainset.collate_fn, shuffle=True)\n",
    "        testloader = DataLoader(testset, batch_size=2, collate_fn=testset.collate_fn)\n",
    "        valloader = DataLoader(valset, batch_size=2, collate_fn=testset.collate_fn)\n",
    "\n",
    "    # Train\n",
    "    best_sr = -np.inf\n",
    "    endure = 0\n",
    "    best_epoch = 0\n",
    "    for epoch in range(int(config['max_epochs'])):\n",
    "        loss = train(model, model_reg, trainloader, optimizer, tokenizer, float(config['lambda_reg']))\n",
    "        accelerator.print(f'========epoch{epoch}; training loss :{loss}=================')\n",
    "        sr = evaluate(model, valloader, tokenizer, accelerator)\n",
    "        accelerator.print(f'========epoch{epoch}; val spearman correlation :{sr}=================')\n",
    "        scheduler.step()\n",
    "        if best_sr > sr:\n",
    "            endure += 1\n",
    "        else:\n",
    "            endure = 0\n",
    "            best_sr = sr\n",
    "            best_epoch = epoch\n",
    "\n",
    "            if not os.path.isdir(f'checkpoint/{dataset}'):\n",
    "                if accelerator.is_main_process:\n",
    "                    os.makedirs(f'checkpoint/{dataset}')\n",
    "            save_path = os.path.join('checkpoint', f'{dataset}',\n",
    "                                        f'seed{args.model_seed}')\n",
    "            accelerator.wait_for_everyone()\n",
    "            unwrapped_model = accelerator.unwrap_model(model)\n",
    "            unwrapped_model.save_pretrained(save_path)\n",
    "        if sr == 1.0:\n",
    "            accelerator.print(f'========early stop at epoch{epoch}!============')\n",
    "            break\n",
    "        if endure > int(config['endure_time']):\n",
    "            accelerator.print(f'========early stop at epoch{epoch}!============')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def training_loop(mixed_precision=\"fp16\", seed: int = 42, batch_size: int = 64):\n",
    "#     set_seed(seed)\n",
    "#     # Initialize accelerator\n",
    "#     accelerator = Accelerator(mixed_precision=mixed_precision)\n",
    "#     # Build dataloaders\n",
    "#     train_dataloader, eval_dataloader = get_dataloaders(batch_size)\n",
    "\n",
    "#     # Instantiate the model (you build the model here so that the seed also controls new weight initaliziations)\n",
    "#     model = create_model(\"resnet50d\", pretrained=True, num_classes=len(label_to_id))\n",
    "\n",
    "#     # Freeze the base model\n",
    "#     for param in model.parameters():\n",
    "#         param.requires_grad = False\n",
    "#     for param in model.get_classifier().parameters():\n",
    "#         param.requires_grad = True\n",
    "\n",
    "#     # You can normalize the batches of images to be a bit faster\n",
    "#     mean = torch.tensor(model.default_cfg[\"mean\"])[None, :, None, None]\n",
    "#     std = torch.tensor(model.default_cfg[\"std\"])[None, :, None, None]\n",
    "\n",
    "#     # To make these constants available on the active device, set it to the accelerator device\n",
    "#     mean = mean.to(accelerator.device)\n",
    "#     std = std.to(accelerator.device)\n",
    "\n",
    "#     # Instantiate the optimizer\n",
    "#     optimizer = torch.optim.Adam(params=model.parameters(), lr=3e-2 / 25)\n",
    "\n",
    "#     # Instantiate the learning rate scheduler\n",
    "#     lr_scheduler = OneCycleLR(optimizer=optimizer, max_lr=3e-2, epochs=5, steps_per_epoch=len(train_dataloader))\n",
    "\n",
    "#     # Prepare everything\n",
    "#     # There is no specific order to remember, you just need to unpack the objects in the same order you gave them to the\n",
    "#     # prepare method.\n",
    "#     model, optimizer, train_dataloader, eval_dataloader, lr_scheduler = accelerator.prepare(\n",
    "#         model, optimizer, train_dataloader, eval_dataloader, lr_scheduler\n",
    "#     )\n",
    "\n",
    "#     # Now you train the model\n",
    "#     for epoch in range(5):\n",
    "#         model.train()\n",
    "#         for batch in train_dataloader:\n",
    "#             inputs = (batch[\"image\"] - mean) / std\n",
    "#             outputs = model(inputs)\n",
    "#             loss = torch.nn.functional.cross_entropy(outputs, batch[\"label\"])\n",
    "#             accelerator.backward(loss)\n",
    "#             optimizer.step()\n",
    "#             lr_scheduler.step()\n",
    "#             optimizer.zero_grad()\n",
    "\n",
    "#         model.eval()\n",
    "#         accurate = 0\n",
    "#         num_elems = 0\n",
    "#         for batch in eval_dataloader:\n",
    "#             inputs = (batch[\"image\"] - mean) / std\n",
    "#             with torch.no_grad():\n",
    "#                 outputs = model(inputs)\n",
    "#             predictions = outputs.argmax(dim=-1)\n",
    "#             accurate_preds = accelerator.gather(predictions) == accelerator.gather(batch[\"label\"])\n",
    "#             num_elems += accurate_preds.shape[0]\n",
    "#             accurate += accurate_preds.long().sum()\n",
    "\n",
    "#         eval_metric = accurate.item() / num_elems\n",
    "#         # Use accelerator.print to print only on the main process.\n",
    "#         accelerator.print(f\"epoch {epoch}: {100 * eval_metric:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import notebook_launcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of EsmForMaskedLM were not initialized from the model checkpoint at facebook/esm1v_t33_650M_UR90S_1 and are newly initialized: ['esm.contact_head.regression.bias', 'esm.contact_head.regression.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of EsmForMaskedLM were not initialized from the model checkpoint at facebook/esm1v_t33_650M_UR90S_1 and are newly initialized: ['esm.contact_head.regression.bias', 'esm.contact_head.regression.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of EsmForMaskedLM were not initialized from the model checkpoint at facebook/esm1v_t33_650M_UR90S_1 and are newly initialized: ['esm.contact_head.regression.bias', 'esm.contact_head.regression.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of EsmForMaskedLM were not initialized from the model checkpoint at facebook/esm1v_t33_650M_UR90S_1 and are newly initialized: ['esm.contact_head.regression.bias', 'esm.contact_head.regression.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "An issue was found when launching the training: \n\n-- Process 0 terminated with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/spawn.py\", line 68, in _wrap\n    fn(i, *args)\n  File \"/usr/local/lib/python3.8/dist-packages/accelerate/utils/launch.py\", line 570, in __call__\n    self.launcher(*args)\n  File \"/tmp/ipykernel_65972/2310528820.py\", line 24, in training_loop\n    model, optimizer, scheduler = accelerator.prepare(model, optimizer, scheduler)\n  File \"/usr/local/lib/python3.8/dist-packages/accelerate/accelerator.py\", line 1228, in prepare\n    result = tuple(\n  File \"/usr/local/lib/python3.8/dist-packages/accelerate/accelerator.py\", line 1229, in <genexpr>\n    self._prepare_one(obj, first_pass=True, device_placement=d) for obj, d in zip(args, device_placement)\n  File \"/usr/local/lib/python3.8/dist-packages/accelerate/accelerator.py\", line 1105, in _prepare_one\n    return self.prepare_model(obj, device_placement=device_placement)\n  File \"/usr/local/lib/python3.8/dist-packages/accelerate/accelerator.py\", line 1356, in prepare_model\n    model = torch.nn.parallel.DistributedDataParallel(\n  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 798, in __init__\n    _verify_param_shape_across_processes(self.process_group, parameters)\n  File \"/usr/local/lib/python3.8/dist-packages/torch/distributed/utils.py\", line 263, in _verify_param_shape_across_processes\n    return dist._verify_params_across_processes(process_group, tensors, logger)\ntorch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1691, unhandled system error (run with NCCL_DEBUG=INFO for details), NCCL version 2.19.3\nncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. \nLast error:\nError while creating shared memory segment /dev/shm/nccl-iEhy0K (size 9637888)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mProcessRaisedException\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/accelerate/launchers.py:200\u001b[0m, in \u001b[0;36mnotebook_launcher\u001b[0;34m(function, args, num_processes, mixed_precision, use_port, master_addr, node_rank, num_nodes)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m     \u001b[43mstart_processes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlauncher\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnprocs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_processes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfork\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ProcessRaisedException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/spawn.py:197\u001b[0m, in \u001b[0;36mstart_processes\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# Loop on join until it returns True or raises an exception.\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/spawn.py:158\u001b[0m, in \u001b[0;36mProcessContext.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    157\u001b[0m msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m original_trace\n\u001b[0;32m--> 158\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ProcessRaisedException(msg, error_index, failed_process\u001b[38;5;241m.\u001b[39mpid)\n",
      "\u001b[0;31mProcessRaisedException\u001b[0m: \n\n-- Process 0 terminated with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/spawn.py\", line 68, in _wrap\n    fn(i, *args)\n  File \"/usr/local/lib/python3.8/dist-packages/accelerate/utils/launch.py\", line 570, in __call__\n    self.launcher(*args)\n  File \"/tmp/ipykernel_65972/2310528820.py\", line 24, in training_loop\n    model, optimizer, scheduler = accelerator.prepare(model, optimizer, scheduler)\n  File \"/usr/local/lib/python3.8/dist-packages/accelerate/accelerator.py\", line 1228, in prepare\n    result = tuple(\n  File \"/usr/local/lib/python3.8/dist-packages/accelerate/accelerator.py\", line 1229, in <genexpr>\n    self._prepare_one(obj, first_pass=True, device_placement=d) for obj, d in zip(args, device_placement)\n  File \"/usr/local/lib/python3.8/dist-packages/accelerate/accelerator.py\", line 1105, in _prepare_one\n    return self.prepare_model(obj, device_placement=device_placement)\n  File \"/usr/local/lib/python3.8/dist-packages/accelerate/accelerator.py\", line 1356, in prepare_model\n    model = torch.nn.parallel.DistributedDataParallel(\n  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 798, in __init__\n    _verify_param_shape_across_processes(self.process_group, parameters)\n  File \"/usr/local/lib/python3.8/dist-packages/torch/distributed/utils.py\", line 263, in _verify_param_shape_across_processes\n    return dist._verify_params_across_processes(process_group, tensors, logger)\ntorch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1691, unhandled system error (run with NCCL_DEBUG=INFO for details), NCCL version 2.19.3\nncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. \nLast error:\nError while creating shared memory segment /dev/shm/nccl-iEhy0K (size 9637888)\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfp16\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m42\u001b[39m, \u001b[38;5;241m16\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mnotebook_launcher\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_loop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_processes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/accelerate/launchers.py:210\u001b[0m, in \u001b[0;36mnotebook_launcher\u001b[0;34m(function, args, num_processes, mixed_precision, use_port, master_addr, node_rank, num_nodes)\u001b[0m\n\u001b[1;32m    203\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    204\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA has been initialized before the `notebook_launcher` could create a forked subprocess. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    205\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis likely stems from an outside import causing issues once the `notebook_launcher()` is called. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    206\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease review your imports and test them when running the `notebook_launcher()` to identify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    207\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhich one is problematic and causing CUDA to be initialized.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    208\u001b[0m                 ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    209\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 210\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn issue was found when launching the training: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;66;03m# No need for a distributed launch otherwise as it's either CPU, GPU or MPS.\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_mps_available():\n",
      "\u001b[0;31mRuntimeError\u001b[0m: An issue was found when launching the training: \n\n-- Process 0 terminated with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/spawn.py\", line 68, in _wrap\n    fn(i, *args)\n  File \"/usr/local/lib/python3.8/dist-packages/accelerate/utils/launch.py\", line 570, in __call__\n    self.launcher(*args)\n  File \"/tmp/ipykernel_65972/2310528820.py\", line 24, in training_loop\n    model, optimizer, scheduler = accelerator.prepare(model, optimizer, scheduler)\n  File \"/usr/local/lib/python3.8/dist-packages/accelerate/accelerator.py\", line 1228, in prepare\n    result = tuple(\n  File \"/usr/local/lib/python3.8/dist-packages/accelerate/accelerator.py\", line 1229, in <genexpr>\n    self._prepare_one(obj, first_pass=True, device_placement=d) for obj, d in zip(args, device_placement)\n  File \"/usr/local/lib/python3.8/dist-packages/accelerate/accelerator.py\", line 1105, in _prepare_one\n    return self.prepare_model(obj, device_placement=device_placement)\n  File \"/usr/local/lib/python3.8/dist-packages/accelerate/accelerator.py\", line 1356, in prepare_model\n    model = torch.nn.parallel.DistributedDataParallel(\n  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/distributed.py\", line 798, in __init__\n    _verify_param_shape_across_processes(self.process_group, parameters)\n  File \"/usr/local/lib/python3.8/dist-packages/torch/distributed/utils.py\", line 263, in _verify_param_shape_across_processes\n    return dist._verify_params_across_processes(process_group, tensors, logger)\ntorch.distributed.DistBackendError: NCCL error in: ../torch/csrc/distributed/c10d/ProcessGroupNCCL.cpp:1691, unhandled system error (run with NCCL_DEBUG=INFO for details), NCCL version 2.19.3\nncclSystemError: System call (e.g. socket, malloc) or external library call failed or device error. \nLast error:\nError while creating shared memory segment /dev/shm/nccl-iEhy0K (size 9637888)\n"
     ]
    }
   ],
   "source": [
    "args = (\"fp16\", 42, 16)\n",
    "notebook_launcher(training_loop, args, num_processes=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
